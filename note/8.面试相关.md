面试氛围还是很不错的，面试官提的很多问题会根据简历上的点提问，然后各种底层原理，框架原理，所以基础不扎实精通的可以不用去浪费时间吧。

面试官的问题：

*问*锁的问题，红黑树，spring bean的周期，加载机制，数据结构hashmap，currentHashmap的原理等，synchronize原理。



 作者：燃烬灰
链接：https://www.nowcoder.com/discuss/159771?type=2
来源：牛客网

大家面了几面(我三面让回去了)
 热乎的面经的
 一面hr面
 了解基本情况(考察学习能力，和薪资要求)
 二面技术面
 struts用来做什么
 arraylist和linkedlist区别
 springMvc流程图
 shiro权限控制
 IOC和AOP
 三面(感觉是大佬)
 问自己做过的项目
 实习经历
 问:你认为怎么样才算是一个好的软件工程师？
 我:懵逼乱答

 总结:基础和写在简历上的东西要说的出来   



平安壹金融的面试

简历上的东西准备的不足

zookeeper可以作为注册中心的原因，什么数据结构

# 消息队列

## 为什么要使用消息队列？或者说消息队列的优点

**解耦、异步、削峰**

### **解耦**

看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......

[![mq-1](https://github.com/wdengf/advanced-java/raw/master/images/mq-1.png)](https://github.com/wdengf/advanced-java/blob/master/images/mq-1.png)

在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！

![mq-2](https://github.com/wdengf/advanced-java/raw/master/images/mq-2.png)







### **异步**

再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD  三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近  1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。

[![mq-3](https://github.com/wdengf/advanced-java/raw/master/images/mq-3.png)](https://github.com/wdengf/advanced-java/blob/master/images/mq-3.png)

一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。

如果**使用 MQ**，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！

![mq-4](https://github.com/wdengf/advanced-java/raw/master/images/mq-4.png)

### 削峰

每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00  ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条  SQL。

一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。

![mq-5](https://github.com/wdengf/advanced-java/raw/master/images/mq-5.png)

如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从  MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A  系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1  个小时），可能有几十万甚至几百万的请求积压在 MQ 中。

[![mq-6](https://github.com/wdengf/advanced-java/raw/master/images/mq-6.png)](https://github.com/wdengf/advanced-java/blob/master/images/mq-6.png)

## 消息队列有什么优缺点

优点上面已经说了，就是**在特殊场景下有其对应的好处**，**解耦**、**异步**、**削峰**。

缺点有以下几个：

- 系统可用性降低
   系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以[点击这里查看](https://github.com/wdengf/advanced-java/blob/master/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md)。
- 系统复杂度提高
   硬生生加个 MQ 进来，你怎么[保证消息没有重复消费](https://github.com/wdengf/advanced-java/blob/master/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed.md)？怎么[处理消息丢失的情况](https://github.com/wdengf/advanced-java/blob/master/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages.md)？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。
- 一致性问题
   A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。

## Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |

综上，各种对比之后，有如下建议：

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量（指在一次性能测试过程中网络上传输的数据量的总和）场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 [Apache](https://github.com/apache/rocketmq)，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

所以**中小型公司**，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；**大型公司**，基础架构研发实力较强，用 RocketMQ 是很好的选择。

如果是**大数据领域**的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。



## 如何保证消息的可靠性传输（处理消息丢失的问题）？

计费，丢了会有很大的损失

rabbitmq这种mq，承载的是核心业务，数据是绝对不能丢的

三个环节

- 生产者写消息的过程，消息没有到mq，mq在网络传输的过程中就丢了；或者消息到了mq，但是mq出错没有保存下来。

- 存到了mq的内存，没来得及消费，mq挂了，导致内存的数据丢了。

- 消费者消费到了这个消息，但是没来得及处理，自己就挂了，但是mq以为这个消费者已经处理完了。

1.生产者搞丢：生产者事务 ，异常就回滚

```java
channel.txSelect
try{
	//发送消息
}catch(Exception e){
	channel.txRollback
	//再次重试发送这条消息
}
channel.txCommit
```

事务机制，同步的，发生消息会卡住，会导致生产者发送消息的吞吐量会降下来

先把channel设置成confirm的模式

发生消息

发生完之后就不用管了

mq如果接受到了这条消息的话，就会回调生产者本地的一个接口，通知你说这条消息我已经收到了

mq如果在接收消息的时候报错了，就会回调你的接口，告诉你这个消息接收失败，可以再次重发

channel.confirm

//发送一个消息

//不用管了

在生产者那里提供一个供回调的一个回调接口的实现

public void ack(String messageId){

}

public void nack(String messageId){

}

生产者这块如果是要保证消息不丢，一般用confirm机制，异步的模式，你发送消息之后不会阻塞，直接发送下一个消息。吞吐量比较高

消息持节化到磁盘上，queue持久化到磁盘上，哪怕是挂了也没事

内存中还未来的及持久化到磁盘上，mq挂了，也会导致丢失，可能性很低

消费者丢失 打开了autoAck机制 你消费到了数据之后，消费者会自动通知rabbitmq，说ok，我已经消费完这条消息了

如果你消费到了一条消息，还在处理中，没有处理玩，此时消费者自动autoAck了，通知mq说这条消息已经消费了。消费者宕机，以为成功消费，其实没有。

关掉autoAck，消费玩后自己手动ack





 



消息队列怎么知道是否成功消费（面试-平安壹金融）

https://blog.csdn.net/u013256816/article/details/55515234



# 缓存Redis

## 项目中缓存是如何使用的？为什么要用缓存？缓存使用不当会造成什么后果？

缓存主要两个用途：**高性能**、**高并发**

**高性能**：开始查询600ms，结果扔缓存里，2ms。对于一些复杂操作耗时查出来的结果，后面不怎么变化的，但是有很多请求的，可以放在缓存中。

**高并发**：mysql这么重的数据库，压根不是让你玩高并发的，虽然可以玩，但是天然支持不好，mysql单机支撑到2000QPS就开始报警了。假如有个系统，高峰期请求1万，mysql死掉。放在缓存，并发量轻松一秒几万十几万。单机承载量是mysql单机的几十倍。

> 缓存是走内存的，内存天然就支撑高并发。

**用了缓存之后会有什么不良后果？**

常见的缓存问题有以下几个：

- 缓存与数据库双写不一致
- 缓存雪崩、缓存穿透
- 缓存并发竞争

**缓存与数据库双写不一致**

一般来说，缓存和数据库不是严格要求一直，最好不要做这个方案。即：**读请求和写请求串行行化**，串到一个内存队列里去。

串行化可以保证一定不会出现不一致的情况，但是会导致系统的吞吐量大幅度降低

Cache Aside Pattern

读的时候先读缓存，缓存没有，读数据库，然后取出数据放到缓存，同时返回响应。更新的时候先更新数据库，然后删除缓存。（为什么是删除？因为复杂的场景缓存不仅仅是数据库取出来的值，可能是计算得到的）

**最初级的缓存不一致问题及解决方案**

问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。

![redis-junior-inconsistent](https://github.com/wdengf/advanced-java/raw/master/images/redis-junior-inconsistent.png)

解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中。

**比较复杂的数据不一致问题分析**

数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，**查到了修改前的旧数据**，放到了缓存中。随后数据变更的程序完成了数据库的修改。完了，数据库和缓存中的数据不一样了...

.........太难了

## redis有哪些数据类型？分别适用的场景？

其实问这个问题，主要有两个原因：

- 看看你到底有没有全面的了解 redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最简单的 KV 操作；
- 看看你在实际项目里都怎么玩儿过 redis。



> 面试 平安壹金融
>
> Redis的除了拿来存储还有什么其他用处，回答了做排行榜的，存储。做排行榜用的什么数据结构，回答的完全不行。大概只说了做缓存，做排行榜。又问你怎么用的。懵逼！

redis的数据类型：

- string
- hash
- list
- set
- sorted set

bin目录下

./redis-cli

连接上redis

**string**

```
set name wanghang

get name

set age 20

incr age

decrby age

String：key-value（做缓存）

--Redis中所有的数据都是字符串。命令不区分大小写，key是区分大小写的。Redis是单线程的。Redis中不适合保存内容大的数据。

get、set、

incr：加一（生成id）

Decr：减一
```

**hash**

相当于一个key对于一个map，map中还有key-value

使用hash对key进行归类。

Hset：向hash中添加内容

Hget：从hash中取内容

```
hset person name bingo
hset person age 20
hset person id 1
hget person name
person = {
    "name": "bingo",
    "age": 20,
    "id": 1
}
```

**list**

有顺序可重复

存储一些列表型的数据结构，类似于粉丝列表、文章的评论列表之类。

通过lrange命令读取区间的值，实现基于list的分页功能

```
# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。
lrange mylist 0 -1

127.0.0.1:6379> lpush mylist 1
(integer) 7
127.0.0.1:6379> lrange mylist 0 -1
1) "1"
2) "5"
3) "4"
4) "3"
5) "2"
6) "2"
7) "1"

```

比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。

```
#加到尾部
lpush mylist 1
lpush mylist 2
lpush mylist 3 4 5

# 1
#尾部弹出
rpop mylist
```

**set**

元素无顺序，自动去重

直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是**如果你的某个系统部署在多台机器上呢？得基于 redis 进行全局的 set 去重**。

可以基于 set 玩儿**交集**、**并集**、**差集**的操作，比如**交集**吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧。

把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。

```
#-------操作一个set-------
# 添加元素
sadd mySet 1

# 查看全部元素
smembers mySet

# 判断是否包含某个值
sismember mySet 3

# 删除某个/些元素
srem mySet 1
srem mySet 2 4

# 查看元素个数
scard mySet

# 随机删除一个元素
spop mySet

#-------操作多个set-------
# 将一个set的元素移动到另外一个set
smove yourSet mySet 2

# 求两set的交集
sinter yourSet mySet

# 求两set的并集
sunion yourSet mySet

# 求在yourSet中而不在mySet中的元素
sdiff yourSet mySet
```

**sorted set**

sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

```
zadd board 85 zhangsan
zadd board 72 lisi
zadd board 96 wangwu
zadd board 63 zhaoliu

# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）
zrevrange board 0 3

# 获取某用户的排名
zrank board zhaoliu
```

## redis 的过期策略都有哪些？内存淘汰机制都有哪些？手写一下 LRU 代码实现？



# Dubbo

## 拆分后不用dubbo可以吗？为什么要用dubbo?

当然可以了，大不了最次各个系统之间直接基于spring mvc，就纯http接口相互通信。但是问题很多，因为http接口通信维护起来成本很高，需要考虑超时重试、负载均衡等乱七八糟的问题。比如说你的订单系统调用商品系统，商品系统部署了 5 台机器，你怎么把请求均匀地甩给那 5 台机器？这不就是负载均衡？你要是都自己搞那是可以的，但是确实很痛苦。

dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡了、服务实例上下线自动感知了、超时重试了，等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。

## 说一下的 dubbo 的工作原理？注册中心挂了可以继续通信吗？说说一次 rpc 请求的流程？

**原理**

- 第一层：service层，接口层，给服务提供者和消费者来实现
- 第二层：config层，配置层，主要对dubbo进行各种配置的
- 第三层：proxy层，服务代理层，无论是consumer还是provider，dubbo都能给你生成代理，代理之进行网络通信
- 第四层：register层，服务注册层，负责服务的注册与发现
- 第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
- 第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控
- 第七层：protocal层，远程调用层，封装rp调用

- 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步
- 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口
- 第十层：serialize 层，数据序列化层

**工作流程**

- 第一步：provider 向注册中心去注册
- 第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务
- 第三步：consumer 调用 provider
- 第四步：consumer 和 provider 都异步通知监控中心

# zookeeper

分布式锁

元素据和配置信息管理

dubbo的注册信息存到zk上，kafka和strom等

HA高可用性场景，监听器，监听挂了，替上，两台机器互为主备



# 简历上的知识点

遇到的难点是 做一个公司一年的业绩情况的统计，分类统计导出

数据量大

分类多

sql语句复杂

业务场景复杂

excel导出的时候出现oom

锐明问项目

难点，做了些什么

内存泄漏



# 加密算法

数据的加密算法有哪些

(1)DES加密算法(数据加密标准)。 

DES是一种对二元数据进行加密的算法，数据分组长度为64位，密文分组长度也是64位，使用的密钥为64位，有效密钥长度为56位，有8位用于奇偶校验，解密时的过程和加密时相似，但密钥的顺序正好相反。 

DES算法的弱点是不能提供足够的安全性，因为其密钥容量只有56位。由于这个原因，后来又提出了三重DES或3DES系统，使用3个不同的密钥对数据块进行(两次或)三次加密，该方法比进行普通加密的三次块。其强度大约和112比特的密钥强度相当。

(2)RSA算法 

RSA算法既能用于数据加密，也能用于数字签名，RSA的理论依据为：寻找两个大素数比较简单，而将它们的乘积分解开则异常困难。在RSA算法中，包含两个密钥，加密密钥PK，和解密密钥SK，加密密钥是公开的，其加密与解密方程为： 

其中n=p×q，P∈[0，n-1]，p和q均为大于10100的素数，这两个素数是保密的。 

RSA算法的优点是密钥空间大，缺点是加密速度慢，如果RSA和DES结合使用，则正好弥补RSA的缺点。即DES用于明文加密，RSA用于DES密钥的加密。由于DES加密速度快，适合加密较长的报文；而RSA可解决DES密钥分配的问题。 

(3)Md5

# 面试过的公司的题目

## 58

58的面试

redis为什么要用到，快在哪？缓存的一致性
项目的难点，简历上要修改
java中用到的数据结构；ArrayList和Vector的区别，
ArrayList为什么不是线程安全的，synchronized和ReTrreLock的区别
手写单例

笔试的一个简答题怎么答