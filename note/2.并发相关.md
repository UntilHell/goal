# 1.类比关键字

## sleep和wait

wait用于线程间的通信，调用后会释放锁，属于Object类

sleep强制线程休眠，但不会释放锁



## start和run

start启动线程，真正实现了多线程；调用后线程处于就绪（可运行）状态，需要等分配CPU时suanfa

run只是类的一个普通方法



# 2.死锁和临界问题

## 1.临界问题

1.甲乙丙3个进程对某类资源的需求分别是7个、8个、3个。且目前已分别得到了3个、3个和2个资源，若系统还至少能提供（  ）个资源，则系统是安全的。

> 丙需要一个，等丙执行完会释放3个，此时甲最多获得6个，因而甲还需要一个才能够正常运行，所以一共需要两个

2.某系统中有3个并发进程，都需要同类资源4 个，试问该系统不会发生死锁的最少资源数是：10

> 3 * （4-1）+ 1 = 10
>
> 3个进程需要各需要占用3个资源，因此当有9个资源时，刚好够分别分给这3个进程，但是这3个进程都还需要第4个资源，因此至少需要10个资源，才不会使其陷入死锁。

3.若系统中有五台绘图仪，有多个进程均需要使用两台，规定每个进程一次仅允许申请一台，则至多允许**（4 ）**个进程参于竞争，而不会发生死锁。

> 4台，当5个进程的时候如果都同时申请到了1台，就发生死锁了。如果是4个进程，那必然有一个能申请到2台。



## 2.死锁产生的原因和四个必要条件

1.原因

![](C:\Users\Administrator\Desktop\note\2.并发相关\deadlock1.png)

产生死锁的原因主要是：
（1） 因为系统资源不足。
（2） 进程运行推进的顺序不合适。
（3） 资源分配不当等。
如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则
就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。
产生死锁的四个必要条件：
（1） 互斥条件：一个资源每次只能被一个进程使用。
（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。
（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之
一不满足，就不会发生死锁。
D选项：共享型设备是指在一段时间内允许多个进程同时访问的设备

2.下列哪种操作可能带来死锁？

A lock(m1) lock(m2) unlock(m1) unlock(m2)
B lock(m1) lock(m2) unlock(m2) lock(m2) unlock(m1) unlock(m2)
C lock(m1) lock(m2) unlock(m1) lock(m1) unlock(m2) unlock(m1)
D lock(m1) lock(m2) unlock(m1) unlock(m2) lock(m1) unlock(m1)

对于序列：lock(m1) lock(m2) unlock(m1) lock(m1) unlock(m2) unlock(m1)，假设有两个操作A，B同时并行执行这个序列，
假设A执行较快，在执行第一个unlock(m1)后，切换到B执行，此时B在执行第一个lock(m1）后请求lock(m2)，但A并未释放m2的锁，导致了**环路等待**的局面，引发死锁。

# 3.进程和线程

多线程为什么能提高效率 2019.9.30

单cpu中，比如有io等待，多线程能提高效率。

程序时间大多花在读取数据上，真正的计算工作花时间还是相对少的，因此cpu很大时间表现都很闲。

pc机不光只一个cpu，cpu和其它硬件设备一起才能完成计算，分工协作，但可能出现其中某个家伙偷懒或效率低，导致大家都等它，闲着的其它设备这个时候可以腾出手来干其它活。

1.

![](C:\Users\Administrator\Desktop\note\2.并发相关\线程状态.png)

运行 -> 等待、就绪
就绪 -> 运行
等待 -> 就绪

![](C:\Users\Administrator\Desktop\note\2.并发相关\线程的生命周期.png)

2.关于进程和线程，以下哪些说明是错误的

A 无论多进程和多线程架构的程序，都可以做到利用CPU多核多线程的能力
B Linux内核看来，进程只是一个资源分配单位，线程才是一个实际的执行体
C 某个进程fork出来的多个子进程，它们的内存是共享的
D 多线程架构的调度开销要小于多进程架构，因此多线程性能会更好一些

正确答案: B C D   你的答案: A B 

B.在Linux中，进程**也是**CPU调度和分配资源的基本单位  

C.**线程才是共享的** 

D多线程比多进程成本低，但性能更低



# 4.线程安全

1.假设某个类有两个成员变量a和b，类型为Integer，以下为某个类中的2个方法，哪些组合是线程安全的?

```java
A. public int sum(){synchronized(this){return a+b;}}
public void set(int a, int b){synchronized(this){this.a=a;this.b=b;}}

B. public synchronized int sum(){return a+b;}
public synchronized void set(int a, int b){this.a=a;this.b=b;}

C. public int sum(){synchronized(this.a){return a+b;}}
public void set(int a, int b){synchronized(this.a){this.a=a;this.b=b;}}

D. public int sum(){synchronized(this.a){return a+b;}}
public void set(int a, int b){synchronized(this.b){this.a=a;this.b=b;}}
```

正确答案: A B   你的答案: B C 

好像是Integer类存在缓存的原因，String也不能作为🔒

2.假设下面的函数foo会被多线程调用，那么让i、j、k三个变量哪些因为线程间共享访问需要加锁保护.() 

```
`int` `i = 0;``void` `foo()``{``    ``static` `int` `j = 0;``    ``int` `k = 0;``    ``i++; j++; k++;``}`
```

A i和j
B i,j,k都需要
C i
D j和k

正确答案: A   你的答案: C 

多线程调用时要进行保护时，主要是针对**全局变量和静态变量的，函数内的局部变量不会受到影响。** 

这里i是全局变量，j是局部静态变量，所以 要进行保护。 

3.竞选条件(race condition)的情况下，两线程执行如下代码段，其中count为共享变量，线程1执行代码段A，线程2指向代码段B，那么变量count的值可能为

```java
int count = 10;
//代码段A：
Thread_1()
{
    //do something
    count++;
}
//代码段B：
Thread_2()
{
    //do something
    count--;
}
```

A 9
B 10
C 11
D 12

正确答案: A B C   你的答案: A B C D 

  ABC   ++和--并非原子操作，存在被打断的可能性。 

  A：线程1先执行，++后数据未及时写入内存便被线程2打断，执行完线程2，数据已被更改，输出9 

  B：顺序正常执行 

  C：线程2先执行，--后数据未及时写入内存便被线程1打断，执行完线程1，数据已被更改，输出11 

# 5.并发和并行

时间片调度属于 __并发__，多线程分别绑定CPU属于 **并行**。

并行：指两个或多个事件在**同一时刻**发生（同时发生）。

并发：指两个或多个事件在**同一个时间段**内发生。

# 6.countdownLatch的使用

countdownLatch

https://www.jianshu.com/p/f17692e9114f

对于倒计数器，一种典型的场景就是火箭发射。在火箭发射前，为了保证万无一失，往往还要进行各项设备、仪器的检测。只有等到所有的检查完毕后，引擎才能点火。那么在检测环节当然是多个检测项可以同时进行的。代码实现：

```java
public class CountDownLatchDemo implements Runnable{

    static final CountDownLatch latch = new CountDownLatch(10);
    static final CountDownLatchDemo demo = new CountDownLatchDemo();


    @Override
    public void run() {
        try {
            Thread.sleep(new Random().nextInt(10) * 1000);
            System.out.println("check complete");
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            latch.countDown();
        }
    }

    public static void main(String[] args) throws InterruptedException{
        ExecutorService exec = Executors.newFixedThreadPool(10);
        for (int i = 0; i < 10; i++) {
            exec.submit(demo);
        }
        latch.await();

        System.out.println("Fire!");
        exec.shutdown();
    }
}

```

上述代码中我们先生成了一个CountDownLatch实例。计数数量为10，这表示需要有10个线程来完成任务，等待在CountDownLatch上的线程才能继续执行。latch.countDown();方法作用是通知CountDownLatch有一个线程已经准备完毕，倒计数器可以减一了。latch.await()方法要求主线程等待所有10个检查任务全部准备好才一起并行执行。

# 7.TPS、吞吐量、并发数、QPS

**TPS**：Transaction Per Second, 每秒事务数, 是衡量系统性能的一个非常重要的指标。

TPS就是每秒事务数，但是事务是基于虚拟用户数的，假如1个虚拟用户在1秒内完成1笔事务，那么TPS明显就是1；如果 
某笔业务响应时间是1ms,那么1个用户在1秒内能完成1000笔事务，TPS就是1000了；如果某笔业务响应时间是1s,那么1个用户在1秒内只能完
成1笔事务，要想达到1000TPS，至少需要1000个用户；因此可以说1个用户可以产生1000TPS，1000个用户也可以产生1000TPS，无非是看响应时间快慢。

**并发数**： 系统同时处理的事务数

**响应时间**：一般取平均响应时间

 TPS=并发用户数 / (响应时间+Thinktime)

# [8.线程池](https://www.jianshu.com/p/c41e942bcd64)

JDK 1.5以后，Java提供一个线程池ThreadPoolExecutor类。下面从构造函数来分析一下这个线程池的使用方法。 

```java
public ThreadPoolExecutor(int corePoolSize, // 1
                              int maximumPoolSize,  // 2
                              long keepAliveTime,  // 3
                              TimeUnit unit,  // 4
                              BlockingQueue<Runnable> workQueue, // 5
                              ThreadFactory threadFactory,  // 6
                              RejectedExecutionHandler handler ) { //7
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    } 
```

| 序号 | 名称            | 类型                     | 含义             |
| ---- | --------------- | ------------------------ | ---------------- |
| 1    | corePoolSize    | int                      | 核心线程池大小   |
| 2    | maximumPoolSize | int                      | 最大线程池大小   |
| 3    | keepAliveTime   | long                     | 线程最大空闲时间 |
| 4    | unit            | TimeUnit                 | 时间单位         |
| 5    | workQueue       | BlockingQueue<Runnable>  | 线程等待队列     |
| 6    | threadFactory   | ThreadFactory            | 线程创建工厂     |
| 7    | handler         | RejectedExecutionHandler | 拒绝策略         |

## **Core and maximum pool sizes 核心和最大线程池数量**

| 参数            | 翻译           |
| --------------- | -------------- |
| corePoolSize    | 核心线程池数量 |
| maximumPoolSize | 最大线程池数量 |

线程池执行器将会根据corePoolSize和maximumPoolSize自动地调整线程池大小。

当在**execute(Runnable)方法中提交新任务并且少于corePoolSize**线程正在运行时，即使**其他工作线程处于空闲状态，也会创建一个新线程来处理该请求**。如果有**多于corePoolSize但小于maximumPoolSize**线程正在运行，**队列未满时，进入队列等待，队列已满时创建新线程**。 通过设置corePoolSize和maximumPoolSize相同，可以创建一个固定大小的线程池。 通过将maximumPoolSize设置为基本上无界的值，例如Integer.MAX_VALUE，可以允许池容纳任意数量的并发任务。 通常，核心和最大池大小仅在构建时设置，但也可以使用`setCorePoolSize`和`setMaximumPoolSize`进行动态更改。

![img](https://upload-images.jianshu.io/upload_images/11183270-a01aea078d7f4178.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200)



## **ThreadFactory 线程工厂**

新线程使用ThreadFactory创建。 如果未另行指定，则使用Executors.defaultThreadFactory默认工厂，使其全部位于同一个ThreadGroup中，并且具有相同的**NORM_PRIORITY优先级**和**非守护进程状态**。

通过提供不同的ThreadFactory，您可以更改线程的名称，线程组，优先级，守护进程状态等。如ThreadCactory在通过从newThread返回null询问时未能创建线程，则执行程序将继续，但可能无法执行任何任务。

线程应该有modifyThread权限。 如果工作线程或使用该池的其他线程不具备此权限，则服务可能会降级：配置更改可能无法及时生效，并且关闭池可能会保持可终止但尚未完成的状态。

## **Keep-alive times 线程存活时间**

如果线程池当前拥有超过corePoolSize的线程，那么多余的线程在空闲时间超过keepAliveTime时会被终止 

## BlockingQueue<Runnable> workQueue

workQueue用于存放提交的任务，队列的实际容量与线程池大小相关联。

- 如果**当前线程池任务线程数量小于核心线程池数量**，执行器总是优先创建一个任务线程，而不是从线程队列中取一个空闲线程。
- 如果**当前线程池任务线程数量大于核心线程池数量**，执行器总是优先从**线程队列中取一个空闲线程**，而不是创建一个任务线程。
- 如果当前**线程池任务线程数量大于核心线程池数量，且队列中无空闲任务线程，将会创建一个任务线程**，**直到超出maximumPoolSize**，如果超时maximumPoolSize，则任务将会被拒绝。

主要有三种队列策略：

1. **Direct handoffs 直接握手队列**
    Direct handoffs 的一个很好的默认选择是 **SynchronousQueue**，它将任务交给线程而不需要保留。这里，如果没有线程立即可用来运行它，那么排队任务的尝试将失败，因此将构建新的线程。此策略在处理可能具有内部依赖关系的请求集时避免锁定。Direct handoffs 通常需要无限制的maximumPoolSizes来避免拒绝新提交的任务。 **但得注意，当任务持续以平均提交速度大余平均处理速度时，会导致线程数量会无限增长问题。**
2. **Unbounded queues 无界队列**
    当所有corePoolSize线程繁忙时，使用无界队列（例如，没有预定义容量的LinkedBlockingQueue）将导致新任务在队列中等待，从而导致maximumPoolSize的值没有任何作用。当每个任务互不影响，完全独立于其他任务时，这可能是合适的;  例如，在网页服务器中， 这种队列方式可以用于平滑瞬时大量请求。**但得注意，当任务持续以平均提交速度大余平均处理速度时，会导致队列无限增长问题。**
3. **Bounded queues 有界队列**
    一个有界的队列（例如，一个ArrayBlockingQueue）和有限的maximumPoolSizes配置有助于防止资源耗尽，但是难以控制。队列大小和maximumPoolSizes需要 **相互权衡**：

- 使用大队列和较小的maximumPoolSizes可以最大限度地减少CPU使用率，操作系统资源和上下文切换开销，但会导致人为的低吞吐量。如果任务经常被阻塞（比如I/O限制），那么系统可以调度比我们允许的更多的线程。
- 使用小队列通常需要较大的maximumPoolSizes，这会使CPU更繁忙，但可能会遇到不可接受的调度开销，这也会降低吞吐量。

## Rejected tasks 拒绝任务

 拒绝任务有两种情况：1. 线程池已经被关闭；2. 任务队列已满且maximumPoolSizes已满；无论哪种情况，都会调用RejectedExecutionHandler的rejectedExecution方法。预定义了四种处理策略：

1.  **AbortPolicy**：默认测策略，抛出RejectedExecutionException运行时异常；
2.  **CallerRunsPolicy**：这提供了一个简单的反馈控制机制，可以减慢提交新任务的速度；
3.  **DiscardPolicy**：直接丢弃新提交的任务；
4.  **DiscardOldestPolicy**：如果执行器没有关闭，队列头的任务将会被丢弃，然后执行器重新尝试执行任务（如果失败，则重复这一过程）；
    我们可以自己定义RejectedExecutionHandler，以适应特殊的容量和队列策略场景中。

**线程池中任务有三种排队策略：**

1. **直接提交：**直接提交策略表示线程池不对任务进行缓存。新进任务直接提交给线程池，当线程池中没有空闲线程时，创建一个新的线程处理此任务。这种策略需要线程池具有无限增长的可能性。实现为：SynchronousQueue
2. **有界队列：**当线程池中线程达到corePoolSize时，新进任务被放在队列里排队等待处理。有界队列（如ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O  边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU  使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。
3. **无界队列：**使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize  线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize  的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web  页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。

**拒绝策略：当任务源源不断的过来，而我们的系统又处理不过来的时候，我们要采取的策略是拒绝服务。RejectedExecutionHandler接口提供了拒绝任务处理的自定义方法的机会。在ThreadPoolExecutor中已经包含四种处理策略。**

1. CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。 
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {  if (!e.isShutdown()) { r.run(); }} 
    这个策略显然不想放弃执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该execute的线程本身来执行。（开始我总不想丢弃任务的执行，但是对某些应用场景来讲，很有可能造成当前线程也被阻塞。如果所有线程都是不能执行的，很可能导致程序没法继续跑了。需要视业务情景而定吧。）
2. AbortPolicy：处理程序遭到拒绝将抛出运行时 RejectedExecutionException 
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {throw new RejectedExecutionException();} 
    这种策略直接抛出异常，丢弃任务。（jdk默认策略，队列满并线程满时直接拒绝添加新任务，并抛出异常，所以说有时候放弃也是一种勇气，为了保证后续任务的正常进行，丢弃一些也是可以接收的，记得做好记录）
3. DiscardPolicy：不能执行的任务将被删除 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {} 这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不抛出异常。
4. DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） 
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) {e.getQueue().poll();e.execute(r); }} 
    该策略就稍微复杂一些，在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务，然后重新尝试运行该任务。这个策略需要适当小心。